"0","# 清理前"
"0","(example_1 <- content(trump_corpus[[2]]) %>% "
"0","    # 只擷取前100個字"
"0","    stringr::word(start = 1, end = 100))"
"1","[1]"
"1"," "" Good evening. Thank you very much. I speak to you today as a lifelong supporter and true friend of Israel. I'm a newcomer to politics, but not to backing the Jewish state.In 2001, weeks after the attacks on New York City and on Washington and frankly, the attacks on all of us, attacks that perpetrated and they were perpetrated by the Islamic fundamentalists, Mayor Rudy Giuliani visited Israel to show solidarity with terror victims. I sent my plane, because I backed the mission for Israel 100 percent.In spring of 2004, at the height of the violence in the Gaza"""
"1","
"
"0","# 清理後"
"0","(example_2 <- content(trump_corpus_clean[[2]]) %>% "
"0","    # 只擷取前100個字"
"0","    stringr::word(start = 1, end = 100))"
"1","[1]"
"1"," "" good evening thank much speak today lifelong supporter true friend israel newcomer politics backing jewish state weeks attacks new york city washington frankly attacks us attacks perpetrated perpetrated islamic fundamentalists mayor rudy giuliani visited israel show solidarity terror victims sent plane backed mission israel percent spring height violence gaza strip grand marshal th salute israel parade largest single gathering support jewish state dangerous time israel frankly anyone supporting israel many people turned honor took risk glad come tonight pander israel politicians talk action believe came speak stand future american relations strategic ally unbreakable friendship cultural brother democracy middle east"""
"1","
"
"0","trump_dtm_clean <- tm::DocumentTermMatrix(trump_corpus_clean)"
"0","clean_freq <- findFreqTerms(trump_dtm_clean, lowfreq = 200)"
"0",""
"0","origin_freq"
"1"," [1]"
"1"," ""about""   "
"1"," ""all""     "
"1"," ""also""    "
"1"," ""america"" "
"1"," ""american"""
"1"," ""and""     "
"1"," ""are""     "
"1"," ""because"" "
"1","
"
"1"," [9]"
"1"," ""been""    "
"1"," ""but""     "
"1"," ""can""     "
"1"," ""clinton"" "
"1"," ""country"" "
"1"," ""don't""   "
"1"," ""every""   "
"1"," ""for""     "
"1","
"
"1","[17]"
"1"," ""from""    "
"1"," ""get""     "
"1"," ""going""   "
"1"," ""great""   "
"1"," ""has""     "
"1"," ""have""    "
"1"," ""her""     "
"1"," ""hillary"" "
"1","
"
"1","[25]"
"1"," ""i'm""     "
"1"," ""into""    "
"1"," ""it's""    "
"1"," ""jobs""    "
"1"," ""just""    "
"1"," ""know""    "
"1"," ""like""    "
"1"," ""make""    "
"1","
"
"1","[33]"
"1"," ""many""    "
"1"," ""more""    "
"1"," ""never""   "
"1"," ""new""     "
"1"," ""not""     "
"1"," ""one""     "
"1"," ""only""    "
"1"," ""our""     "
"1","
"
"1","[41]"
"1"," ""out""     "
"1"," ""people""  "
"1"," ""she""     "
"1"," ""than""    "
"1"," ""that""    "
"1"," ""the""     "
"1"," ""their""   "
"1"," ""these""   "
"1","
"
"1","[49]"
"1"," ""they""    "
"1"," ""this""    "
"1"," ""trade""   "
"1"," ""united""  "
"1"," ""very""    "
"1"," ""want""    "
"1"," ""was""     "
"1"," ""what""    "
"1","
"
"1","[57]"
"1"," ""when""    "
"1"," ""who""     "
"1"," ""will""    "
"1"," ""with""    "
"1"," ""you""     "
"1"," ""your""    "
"1","
"
"0","clean_freq"
"1"," [1]"
"1"," ""also""      "
"1"," ""america""   "
"1"," ""american""  "
"1"," ""back""      "
"1"," ""can""       "
"1"," ""clinton""   "
"1"," ""country""   "
"1","
"
"1"," [8]"
"1"," ""every""     "
"1"," ""get""       "
"1"," ""going""     "
"1"," ""government"""
"1"," ""great""     "
"1"," ""hillary""   "
"1"," ""jobs""      "
"1","
"
"1","[15]"
"1"," ""just""      "
"1"," ""know""      "
"1"," ""like""      "
"1"," ""make""      "
"1"," ""many""      "
"1"," ""never""     "
"1"," ""new""       "
"1","
"
"1","[22]"
"1"," ""now""       "
"1"," ""one""       "
"1"," ""people""    "
"1"," ""president"" "
"1"," ""said""      "
"1"," ""state""     "
"1"," ""states""    "
"1","
"
"1","[29]"
"1"," ""time""      "
"1"," ""trade""     "
"1"," ""trump""     "
"1"," ""united""    "
"1"," ""want""      "
"1"," ""will""      "
"1"," ""world""     "
"1","
"
"0","# 資料清理後，甚至出現了原先高詞頻中沒出現的字。"
"0","setdiff(clean_freq, origin_freq)"
"1"," [1]"
"1"," ""back""      "
"1"," ""government"""
"1"," ""now""       "
"1"," ""president"" "
"1"," ""said""      "
"1"," ""state""     "
"1"," ""states""    "
"1","
"
"1"," [8]"
"1"," ""time""      "
"1"," ""trump""     "
"1"," ""world""     "
"1","
"
