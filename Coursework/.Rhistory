green_co_word
set.seed(2222)
green_co_word <- textplot_network(green_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛綠萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: LTN/FTV") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
green_co_word
set.seed(30)
green_co_word <- textplot_network(green_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛綠萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: LTN/FTV") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
green_co_word
set.seed(30)
green_co_word <- textplot_network(green_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛綠萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: LTN/FTV") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
green_co_word
set.seed(2222)
green_co_word <- textplot_network(green_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛綠萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: LTN/FTV") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
green_co_word
set.seed(2049)
green_co_word <- textplot_network(green_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛綠萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: LTN/FTV") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
green_co_word
set.seed(29)
green_co_word <- textplot_network(green_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛綠萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: LTN/FTV") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
green_co_word
set.seed(30)
green_co_word <- textplot_network(green_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛綠萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: LTN/FTV") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
green_co_word
set.seed(232)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(222)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(2222)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(2332)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(232)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(2351)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(231)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(230)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(29)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(30)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(233)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(232)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(30)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(232)
blue_co_word <- textplot_network(blue_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛藍萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: Chinatimes/TVBS") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
blue_co_word
set.seed(2222)
green_co_word <- textplot_network(green_fcm_top, min_freq = 0.85,
vertex_size = size / max(size) * 3,
vertex_labelsize = 6,
vertex_labelcolor = "red") +
labs(title = "泛綠萊豬詞共現關聯圖",
subtitle = "2020/8-2021/12",
caption = "Source: LTN/FTV") +
theme(plot.title = element_text(hjust = 0.5, size = 25),
plot.subtitle = element_text(hjust = 0.5, size = 15),
plot.caption = element_text(size = 15))
green_co_word
install.packages("DT")
library(shiny)
library(tidyverse)
library(tidytext)
library(DT) # ins
install.packages('rsconnect')
runApp('shiny app')
ukraine <- read.csv(file = "data/UkraineCombinedTweetsDeduped20220227-131611.csv")
head(ukraine)
View(ukraine)
library("dplyr")
ukraine <- ukraine %>%
filter(language = "en")
ukraine <- ukraine %>%
filter(language == "en")
View(ukraine)
load("data/final/Ractopamine_Pork.RData")
library(rtweet)
install.packages("rtweet")
library(rtweet)
UA <- search_tweets("#Ukraine", n = 100, include_rts = FALSE, lang = "ua")
auth_setup_default()
UA <- search_tweets("#Ukraine", n = 100, include_rts = FALSE, lang = "ua")
UA <- search_tweets(n = 100, include_rts = FALSE, lang = "ua")
UA <- search_tweets("Україна", n = 100, include_rts = FALSE, lang = "ua")
UA <- search_tweets("#Україна", n = 100, include_rts = FALSE, lang = "ua")
UA <- search_tweets("#Україна", n = 100, include_rts = FALSE)
View(UA)
View(UA[[17]][[1]])
library(tidyverse)
library(jiebaR)
library(ropencc)
load(file = "data/nao.RData")
View(data_all)
# 初始化斷詞引擎
tokenizer <- worker()
data_all %>%
mutate(fulltext = str_replace_all(string = fulltext,
pattern = "[0-9]+",
replacement = ""))
data_all %>%
mutate(fulltext = str_replace_all(string = fulltext,
pattern = "[0-9]+",
replacement = "")) %>%
mutate(tokens = segment(code = fulltext,
jiebar = tokenizer))
data_tokenized <- data_all %>%
mutate(fulltext = str_replace_all(string = fulltext,
pattern = "[0-9]+",
replacement = "")) %>%
mutate(tokens = segment(code = fulltext,
jiebar = tokenizer))
data_all %>%
mutate(fulltext = str_replace_all(string = fulltext,
pattern = "[0-9]+",
replacement = "")) %>%
mutate(tokens = segment(code = fulltext,
jiebar = tokenizer)) %>%
unnest()
# 初始化斷詞引擎
tokenizer <- worker(bylines = 1)
data_all %>%
mutate(fulltext = str_replace_all(string = fulltext,
pattern = "[0-9]+",
replacement = "")) %>%
mutate(tokens = segment(code = fulltext,
jiebar = tokenizer))
data_tokenized <- data_all %>%
mutate(fulltext = str_replace_all(string = fulltext,
pattern = "[0-9]+",
replacement = "")) %>%
mutate(tokens = segment(code = fulltext,
jiebar = tokenizer)) %>%
unnest() # 將tokens(list column)展開，令每一列都只有一個token。
View(data_tokenized)
# 檢查
class(data_tokenized$fulltext)
class(data_tokenized$tokens)
zh_stopwords <- tibble(stopword = stopwords::stopwords(language = "zh", source = "misc"))
View(zh_stopwords)
trans <- converter(S2TWP)
zh_stopwords$stopword <- run_convert(trans, zh_stopwords$stopword)
# 自訂停詞(因為是先去除數字才斷詞，所以"年", "月", "日"可能會合併成"年月日"，故新增此項)
custom <- tibble(stopword = c("年", "月", "日", "民國", "與", "於", "並", "為", "項", "年月日"))
View(custom)
rbind(zh_stopwords, custom)
custom_stopwords <- rbind(zh_stopwords, custom)
# 去除停詞
data_token_clean <- data_tokenized %>%
anti_join(custom_stopwords, by = c("tokens" = "stopword"))
View(data_token_clean)
data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}")) %>%
select(title, year, tokens) %>%
# 按年分組計算並挑選出前十高詞頻
group_by(year) %>%
count(tokens)
data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}"))
data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}")) %>%
select(title, year, tokens)
data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}")) %>%
select(title, year, tokens) %>%
# 按年分組計算並挑選出前十高詞頻
group_by(year)
data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}")) %>%
select(title, year, tokens) %>%
# 按年分組計算並挑選出前十高詞頻
group_by(year) %>%
count(tokens)
data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}")) %>%
select(title, year, tokens) %>%
# 按年分組計算並挑選出前十高詞頻
group_by(year) %>%
count(tokens) %>%
arrange(desc(n))
data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}")) %>%
select(title, year, tokens) %>%
# 按年分組計算並挑選出前十高詞頻
group_by(year) %>%
count(tokens) %>%
arrange(desc(n)) %>%
slice_head(n = 10)
data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}")) %>%
select(title, year, tokens) %>%
# 按年分組計算並挑選出前十高詞頻
group_by(year) %>%
count(tokens) %>%
arrange(desc(n)) %>%
slice_head(n = 10) %>%
ungroup()
top10_year <- data_token_clean %>%
# 篩出year的變項，並清理dataframe
mutate(year = str_extract(string = date,
pattern = "\\d{4}")) %>%
select(title, year, tokens) %>%
# 按年分組計算並挑選出前十高詞頻
group_by(year) %>%
count(tokens) %>%
arrange(desc(n)) %>%
slice_head(n = 10) %>%
ungroup()
View(top10_year)
ggplot(top10_year) +
geom_bar(aes(x=tidytext::reorder_within(x = tokens, by = n, within = year), y=n, fill = year), stat = "identity") +
tidytext::scale_x_reordered() +
# 以year為類別變項繪製圖表
facet_wrap(vars(year), scales = "free_y") +
# 增加標題、xy軸名稱
labs(title = "審計部常用詞彙",
x = "tokens",
y = "count") +
# 翻轉xy軸
coord_flip()
ggplot(top10_year) +
geom_bar(aes(x=tidytext::reorder_within(x = tokens, by = n, within = year), y=n, fill = year), stat = "identity") +
tidytext::scale_x_reordered() +
# 以year為類別變項繪製圖表
facet_wrap(vars(year), scales = "free_y") +
# 增加標題、xy軸名稱
labs(title = "審計部常用詞彙",
x = "tokens",
y = "count") +
# 翻轉xy軸
coord_flip() +
# 更改主題樣式
theme_bw() +
# 移除圖例
theme(legend.position = "none")
load("data/final/Summarized_Ractopamine_Pork.RData")
library(tidyverse)
library(jiebaR)
library(ropencc)
trans <- converter(S2TWP)
zh_stopwords <- stopwords::stopwords(language = "zh", source = "misc")
zh_stopwords <- run_convert(trans, zh_stopwords)
zh_stopwords <- tibble(stopwords = zh_stopwords)
custom <- tibble(stopwords = c("與", "於", "並", "為", "項",
"案", "有", "有些", "件", "豬在",
"七點", "自可", "拉克", "一斤", "這跟",
"這一", "美的", "逾", "值將", "圖說",
"保基", "及齡", "天將", "二二", "一年",
"一一", "九比", "之友", "不換", "給點",
"更是", "一再", "沒有", "一步", "在內",
"Act", "QPP", "SOGO", "home", "stay",
"KEYPO", "the", "Pet", "Stop", "Clinic"))
custom_stopwords <- rbind(zh_stopwords, custom)
# 建立斷詞引擎
tokenizer <- worker(bylines = 1, user = "data/final/userdict.txt")
pork_tokenized <- pork_df %>%
mutate(tokens = segment(code = clean_content, jiebar = tokenizer)) %>%
unnest(cols = c(tokens)) %>%
anti_join(custom_stopwords, by = c("tokens" = "stopwords")) %>%
select(id, date, stance, tokens) %>%
filter(nchar(tokens) > 1)
View(pork_tokenized)
pork_tokenized %>%
count(tokens, stance)
pork_tokenized %>%
count(tokens, stance) %>%
filter(n >= 2000) %>%
spread(stance, n, fill = 0)
pork_tokenized %>%
count(tokens, stance) %>%
filter(n >= 2000) %>%
spread(stance, n, fill = 0) %>%
ungroup() %>%
mutate(across(-tokens, ~ ((. + 1) / sum(. + 1))
))
pork_tokenized %>%
count(tokens, stance) %>%
filter(n >= 2000) %>%
spread(stance, n, fill = 0) %>%
ungroup() %>% across(-tokens, ~ ((. + 1) / sum(. + 1))
)
pork_odds <- pork_tokenized %>%
count(tokens, stance) %>%
filter(n >= 2000) %>%
spread(stance, n, fill = 0) %>%
ungroup() %>%
mutate(across(-tokens, ~ ((. + 1) / sum(. + 1))
)) %>%
mutate(logratio = log2(blue / green)) %>%
arrange(desc(logratio))
View(pork_odds)
